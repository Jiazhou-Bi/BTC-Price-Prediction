{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preamble ####\n",
    "# Purpose: Cleans, engineers, and saves the cleaned data \n",
    "# Author: Jiazhou(Justin) Bi\n",
    "# Date: 15 Nov 2024\n",
    "# Contact: justin.bi@mail.utoronto.ca\n",
    "# License: None\n",
    "# Pre-requisites: see requirements.txt\n",
    "# Any other information needed? None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets as DataFrame\n",
    "df_1m = pd.read_parquet('../data/01-raw_data/raw_data_1m.parquet')\n",
    "df_1h = pd.read_parquet('../data/01-raw_data/raw_data_1h.parquet')\n",
    "df_1d = pd.read_parquet('../data/01-raw_data/raw_data_1d.parquet')\n",
    "# print(df_1m.head())\n",
    "# print(df_1h.head())\n",
    "# print(df_1d.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "open         0\n",
       "high         0\n",
       "low          0\n",
       "close        0\n",
       "volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1m.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "open         0\n",
       "high         0\n",
       "low          0\n",
       "close        0\n",
       "volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "open         0\n",
       "high         0\n",
       "low          0\n",
       "close        0\n",
       "volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1d.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values found in these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section examines the datatypes of each column and ensures they are appropriate for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    datetime64[ns]\n",
       "open                float64\n",
       "high                float64\n",
       "low                 float64\n",
       "close               float64\n",
       "volume              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1m.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    datetime64[ns]\n",
       "open                float64\n",
       "high                float64\n",
       "low                 float64\n",
       "close               float64\n",
       "volume              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    datetime64[ns]\n",
       "open                float64\n",
       "high                float64\n",
       "low                 float64\n",
       "close               float64\n",
       "volume              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is to validate if the datasets are consecutive. That is, for the 1-minute timestamp dataset, no minutes should be skipped. Same logic appleis to the 1-hour and 1-day timestamp datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating if any minute is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melty\\AppData\\Local\\Temp\\ipykernel_15184\\1966021032.py:2: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  full_minute_range = pd.date_range(start=df_1m['timestamp'].min(), end=df_1m['timestamp'].max(), freq='1T')\n"
     ]
    }
   ],
   "source": [
    "# creating a full range of minutes for the 1-minute dataset\n",
    "full_minute_range = pd.date_range(start=df_1m['timestamp'].min(), end=df_1m['timestamp'].max(), freq='1T')\n",
    "# print(full_minute_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexing the DataFrame\n",
    "df_1m.set_index('timestamp', inplace=True)\n",
    "df_1m = df_1m.reindex(full_minute_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps: DatetimeIndex([], dtype='datetime64[ns]', freq='min')\n"
     ]
    }
   ],
   "source": [
    "missing_timestamps = full_minute_range.difference(df_1m.index)\n",
    "print(\"Missing timestamps:\", missing_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows:\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, open, high, low, close, volume]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "missing_rows = pd.DataFrame(index=missing_timestamps, columns=df_1m.columns)\n",
    "missing_rows.reset_index(inplace=True)\n",
    "missing_rows.rename(columns={'index': 'timestamp'}, inplace=True)\n",
    "print(\"Missing rows:\")\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS: All timestamps match.\n"
     ]
    }
   ],
   "source": [
    "if set(full_minute_range) == set(df_1m.index):\n",
    "    print(\"PASS: All timestamps match.\")\n",
    "else:\n",
    "    print(\"FAIL: There are mismatched timestamps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating if any hour is missing from the 1-hour dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps: DatetimeIndex([], dtype='datetime64[ns]', freq='h')\n"
     ]
    }
   ],
   "source": [
    "# using the same logic as above\n",
    "full_hour_range = pd.date_range(start=df_1h['timestamp'].min(), end=df_1h['timestamp'].max(), freq='1h')\n",
    "df_1h.set_index('timestamp', inplace=True)\n",
    "df_1h = df_1h.reindex(full_hour_range)\n",
    "missing_timestamps_hour = full_hour_range.difference(df_1h.index)\n",
    "print(\"Missing timestamps:\", missing_timestamps_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows:\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, open, high, low, close, volume]\n",
      "Index: []\n",
      "PASS: All timestamps match.\n"
     ]
    }
   ],
   "source": [
    "missing_rows_hour = pd.DataFrame(index=missing_timestamps_hour, columns=df_1h.columns)\n",
    "missing_rows_hour.reset_index(inplace=True)\n",
    "missing_rows_hour.rename(columns={'index': 'timestamp'}, inplace=True)\n",
    "print(\"Missing rows:\")\n",
    "print(missing_rows_hour)\n",
    "\n",
    "if set(full_hour_range) == set(df_1h.index):\n",
    "    print(\"PASS: All timestamps match.\")\n",
    "else:\n",
    "    print(\"FAIL: There are mismatched timestamps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating if any day is missing from the 1-day dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps: DatetimeIndex([], dtype='datetime64[ns]', freq='D')\n",
      "Missing rows:\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, open, high, low, close, volume]\n",
      "Index: []\n",
      "PASS: All timestamps match.\n"
     ]
    }
   ],
   "source": [
    "# using the same logic as above\n",
    "full_day_range = pd.date_range(start=df_1d['timestamp'].min(), end=df_1d['timestamp'].max(), freq='1d')\n",
    "df_1d.set_index('timestamp', inplace=True)\n",
    "df_1d = df_1d.reindex(full_day_range)\n",
    "missing_timestamps_day = full_day_range.difference(df_1d.index)\n",
    "print(\"Missing timestamps:\", missing_timestamps_day)\n",
    "\n",
    "missing_rows_day = pd.DataFrame(index=missing_timestamps_day, columns=df_1d.columns)\n",
    "missing_rows_day.reset_index(inplace=True)\n",
    "missing_rows_day.rename(columns={'index': 'timestamp'}, inplace=True)\n",
    "print(\"Missing rows:\")\n",
    "print(missing_rows_day)\n",
    "\n",
    "if set(full_day_range) == set(df_1d.index):\n",
    "    print(\"PASS: All timestamps match.\")\n",
    "else:\n",
    "    print(\"FAIL: There are mismatched timestamps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding A Column For Price Change Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subsection creates a new column for each dataset called direction. If the closing price is higher than the previous closing price, it is considered that the price has gone up and thus marked as 1 for appreciation. If the closing price is lower than the previous closing price, it is considered that the price has gone down and hence is marked as -1 for depreciation. If the price remains the same,  it is marked as 0 for no movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculting the direction\n",
    "df_1m['direction'] = df_1m['close'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "\n",
    "# Dropping the first row as it does not have a direction\n",
    "df_1m.reset_index(inplace=True)\n",
    "df_1m = df_1m.iloc[1:].reset_index(drop=True)\n",
    "#df_1m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the same logic to the 1-hour and 1-day datasets\n",
    "df_1h['direction'] = df_1h['close'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "df_1h.reset_index(inplace=True)\n",
    "df_1h = df_1h.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "df_1d['direction'] = df_1d['close'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "df_1d.reset_index(inplace=True)\n",
    "df_1d = df_1d.iloc[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the DataFrame as a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1m.to_parquet('../data/02-analysis_data/cleaned_data_1m.parquet', index=False)\n",
    "df_1h.to_parquet('../data/02-analysis_data/cleaned_data_1h.parquet', index=False)\n",
    "df_1d.to_parquet('../data/02-analysis_data/cleaned_data_1d.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
