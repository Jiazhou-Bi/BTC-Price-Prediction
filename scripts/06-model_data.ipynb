{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preamble ####\n",
    "# Purpose: Model the data to predict BTC/USTD's moving direction\n",
    "# Author: Jiazhou(Justin) Bi\n",
    "# Date: 14 Nov 2024\n",
    "# Contact: justin.bi@mail.utoronto.ca\n",
    "# License: None\n",
    "# Pre-requisites: see requirements.txt\n",
    "# Any other information needed? None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('../data/01-raw_data/raw_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing necessary packages\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melty\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# creating a copy of the original data to be used by RNN\n",
    "df_RNN = df.drop(columns=['timestamp',])\n",
    "\n",
    "# defining the target variable\n",
    "df_RNN ['target'] = df_RNN['close'].shift(-1)\n",
    "df_RNN.dropna(inplace=True) # dropping the last row as it is missing the target variable\n",
    "\n",
    "# defining features and target\n",
    "X = df_RNN[['close', 'open', 'high', 'low', 'volume']]\n",
    "y = df_RNN['target']\n",
    "\n",
    "# Scale the features and target\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_RNN)\n",
    "\n",
    "# Create sequences for RNN (60 rows at the moment)\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length, :-1])  # Use all columns except the last one (target)\n",
    "        y.append(data[i + sequence_length, -1])     # The target column is the last one\n",
    "    return np.array(X), np.array(y)\n",
    "sequence_length = 60\n",
    "X, y = create_sequences(df_scaled, sequence_length)\n",
    "\n",
    "# Split data into training and test sets\n",
    "split_ratio = 0.7\n",
    "split_index = int(len(X) * split_ratio)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# defining the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(64, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 9ms/step - loss: 2.7066e-04 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 1.1640e-05 - val_loss: 0.0064\n",
      "Epoch 3/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 9ms/step - loss: 6.6797e-06 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 6.3167e-06 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 5.9226e-06 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 9ms/step - loss: 5.7484e-06 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 9ms/step - loss: 5.9153e-06 - val_loss: 0.0062\n",
      "Epoch 8/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 9ms/step - loss: 8.7678e-06 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 5.8209e-06 - val_loss: 0.0220\n",
      "Epoch 10/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 9ms/step - loss: 4.2654e-06 - val_loss: 0.0201\n",
      "Epoch 11/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 9ms/step - loss: 3.9133e-06 - val_loss: 0.0163\n",
      "Epoch 12/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 3.7060e-06 - val_loss: 0.0204\n",
      "Epoch 13/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 9ms/step - loss: 3.9460e-06 - val_loss: 0.0202\n",
      "Epoch 14/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 1.1328e-05 - val_loss: 0.0235\n",
      "Epoch 15/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 9ms/step - loss: 4.3376e-06 - val_loss: 0.0158\n",
      "Epoch 16/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 9ms/step - loss: 5.3210e-06 - val_loss: 0.0188\n",
      "Epoch 17/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 9ms/step - loss: 3.2044e-06 - val_loss: 0.0165\n",
      "Epoch 18/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 6.9405e-06 - val_loss: 0.0157\n",
      "Epoch 19/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 4.5253e-06 - val_loss: 0.0151\n",
      "Epoch 20/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 9ms/step - loss: 3.6416e-06 - val_loss: 0.0154\n",
      "Epoch 21/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 418.1321 - val_loss: 0.0062\n",
      "Epoch 22/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 1.1011e-05 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 9ms/step - loss: 5.8676e-06 - val_loss: 0.0059\n",
      "Epoch 24/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 6.7235e-06 - val_loss: 0.0064\n",
      "Epoch 25/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 7.0231e-06 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 5.3080e-06 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 9ms/step - loss: 7.1200e-06 - val_loss: 0.0060\n",
      "Epoch 28/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 9ms/step - loss: 5.4023e-06 - val_loss: 0.0058\n",
      "Epoch 29/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 9ms/step - loss: 6.4879e-06 - val_loss: 0.0057\n",
      "Epoch 30/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 9ms/step - loss: 6.2317e-06 - val_loss: 0.0057\n",
      "Epoch 31/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 6.2276e-06 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 6.1038e-06 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 9ms/step - loss: 6.9984e-06 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 9ms/step - loss: 6.5794e-06 - val_loss: 0.0057\n",
      "Epoch 35/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 9ms/step - loss: 6.5018e-06 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9ms/step - loss: 5.9601e-06 - val_loss: 0.0057\n",
      "Epoch 37/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 9ms/step - loss: 6.0776e-06 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 9ms/step - loss: 6.0303e-06 - val_loss: 0.0057\n",
      "Epoch 39/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 9ms/step - loss: 5.6044e-06 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 9ms/step - loss: 5.7670e-06 - val_loss: 0.0057\n",
      "Epoch 41/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 9ms/step - loss: 6.4162e-06 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 9ms/step - loss: 5.8808e-06 - val_loss: 0.0057\n",
      "Epoch 43/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 10ms/step - loss: 5.4895e-06 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 10ms/step - loss: 6.5057e-06 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 10ms/step - loss: 4.9662e-06 - val_loss: 0.0057\n",
      "Epoch 46/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 10ms/step - loss: 4.9879e-06 - val_loss: 0.0057\n",
      "Epoch 47/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 9ms/step - loss: 5.7151e-06 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 9ms/step - loss: 5.9162e-06 - val_loss: 0.0057\n",
      "Epoch 49/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 9ms/step - loss: 5.2012e-06 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "\u001b[1m83183/83183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 9ms/step - loss: 5.2791e-06 - val_loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35650/35650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - loss: 0.0062\n",
      "Test Loss: 0.005694008432328701\n",
      "\u001b[1m35650/35650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1140785,5) (6,) (1140785,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m X_test_last_step \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X_test[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dummy_column], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Reconstruct predictions for inverse scaling\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m predicted_prices \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test_last_step\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     16\u001b[0m actual_prices \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(\n\u001b[0;32m     17\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate([X_test_last_step[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m )[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(14, 5))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# plt.plot(actual_prices, color='blue', label='Actual BTC Price')\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# plt.plot(predicted_prices, color='red', label='Predicted BTC Price')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# plt.legend()\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\melty\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:574\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    564\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    566\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    567\u001b[0m     X,\n\u001b[0;32m    568\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    571\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    575\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1140785,5) (6,) (1140785,5) "
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "dummy_column = np.zeros((X_test.shape[0], 1))\n",
    "X_test_last_step = np.concatenate([X_test[:, -1, :-1], dummy_column], axis=1)\n",
    "\n",
    "# Reconstruct predictions for inverse scaling\n",
    "predicted_prices = scaler.inverse_transform(\n",
    "    np.concatenate([X_test_last_step[:, :-1], predictions], axis=1)\n",
    ")[:, -1]\n",
    "\n",
    "actual_prices = scaler.inverse_transform(\n",
    "    np.concatenate([X_test_last_step[:, :-1], y_test.reshape(-1, 1)], axis=1)\n",
    ")[:, -1]\n",
    "\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# plt.plot(actual_prices, color='blue', label='Actual BTC Price')\n",
    "# plt.plot(predicted_prices, color='red', label='Predicted BTC Price')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('BTC Price')\n",
    "# plt.title('Actual vs Predicted BTC Price')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
